{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파이토치로 다층 퍼셉트론 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# GPU가 사용 가능한지 여부 파악\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xor 문제를 풀기 위한 입력 과 출력 정의\n",
    "x = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "y = [[0], [1], [1], [0]]\n",
    "\n",
    "x = torch.tensor(x, dtype=torch.float32).to(device)\n",
    "y = torch.tensor(y, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=2, out_features=10, bias=True)\n",
      "  (1): Sigmoid()\n",
      "  (2): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (3): Sigmoid()\n",
      "  (4): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (5): Sigmoid()\n",
      "  (6): Linear(in_features=10, out_features=1, bias=True)\n",
      "  (7): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "# 입력층, 은닉층1,2,3, 출력층\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 10, bias=True), # input layer = 2, hidden layer 1 --> 10\n",
    "    nn.Sigmoid(), # activation function\n",
    "    nn.Linear(10, 10, bias=True), # hidden layer 1 = 10, hidden layer 2 = 10\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(10, 10, bias=True), # hidden layer 2 = 10, hidden layer 3 = 10\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(10, 1, bias=True), # hidden layer 3 = 10, output layer = 1\n",
    "    nn.Sigmoid() # 사용할 Loss가 BCELoss이므로, 마지막 레이어에 sigmoid 함수 적용\n",
    ").to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, loss : 0.7144914865493774\n",
      "Epoch : 1000, loss : 0.6931343674659729\n",
      "Epoch : 2000, loss : 0.6931332349777222\n",
      "Epoch : 3000, loss : 0.693132221698761\n",
      "Epoch : 4000, loss : 0.6931310296058655\n",
      "Epoch : 5000, loss : 0.69312983751297\n",
      "Epoch : 6000, loss : 0.6931285858154297\n",
      "Epoch : 7000, loss : 0.6931272149085999\n",
      "Epoch : 8000, loss : 0.69312584400177\n",
      "Epoch : 9000, loss : 0.6931242942810059\n",
      "Epoch : 10000, loss : 0.6931227445602417\n",
      "Epoch : 11000, loss : 0.693121075630188\n",
      "Epoch : 12000, loss : 0.6931192874908447\n",
      "Epoch : 13000, loss : 0.6931174397468567\n",
      "Epoch : 14000, loss : 0.6931154131889343\n",
      "Epoch : 15000, loss : 0.6931131482124329\n",
      "Epoch : 16000, loss : 0.6931107640266418\n",
      "Epoch : 17000, loss : 0.6931082010269165\n",
      "Epoch : 18000, loss : 0.6931053996086121\n",
      "Epoch : 19000, loss : 0.6931023001670837\n",
      "Epoch : 20000, loss : 0.6930989027023315\n",
      "Epoch : 21000, loss : 0.6930950880050659\n",
      "Epoch : 22000, loss : 0.693091094493866\n",
      "Epoch : 23000, loss : 0.6930864453315735\n",
      "Epoch : 24000, loss : 0.6930813789367676\n",
      "Epoch : 25000, loss : 0.6930755972862244\n",
      "Epoch : 26000, loss : 0.6930691003799438\n",
      "Epoch : 27000, loss : 0.6930617094039917\n",
      "Epoch : 28000, loss : 0.6930533051490784\n",
      "Epoch : 29000, loss : 0.6930437088012695\n",
      "Epoch : 30000, loss : 0.6930323839187622\n",
      "Epoch : 31000, loss : 0.6930192708969116\n",
      "Epoch : 32000, loss : 0.6930036544799805\n",
      "Epoch : 33000, loss : 0.6929850578308105\n",
      "Epoch : 34000, loss : 0.6929625868797302\n",
      "Epoch : 35000, loss : 0.6929348707199097\n",
      "Epoch : 36000, loss : 0.6929004788398743\n",
      "Epoch : 37000, loss : 0.6928566694259644\n",
      "Epoch : 38000, loss : 0.6927996873855591\n",
      "Epoch : 39000, loss : 0.6927237510681152\n",
      "Epoch : 40000, loss : 0.6926191449165344\n",
      "Epoch : 41000, loss : 0.6924692392349243\n",
      "Epoch : 42000, loss : 0.6922432780265808\n",
      "Epoch : 43000, loss : 0.6918795108795166\n",
      "Epoch : 44000, loss : 0.691238522529602\n",
      "Epoch : 45000, loss : 0.6899502873420715\n",
      "Epoch : 46000, loss : 0.6867591142654419\n",
      "Epoch : 47000, loss : 0.6752901673316956\n",
      "Epoch : 48000, loss : 0.6087097525596619\n",
      "Epoch : 49000, loss : 0.18935763835906982\n",
      "Epoch : 50000, loss : 0.013648013584315777\n",
      "Epoch : 51000, loss : 0.005461325868964195\n",
      "Epoch : 52000, loss : 0.0032390160486102104\n",
      "Epoch : 53000, loss : 0.002255203202366829\n",
      "Epoch : 54000, loss : 0.0017116512171924114\n",
      "Epoch : 55000, loss : 0.0013706139288842678\n",
      "Epoch : 56000, loss : 0.0011382856173440814\n",
      "Epoch : 57000, loss : 0.0009705385891720653\n",
      "Epoch : 58000, loss : 0.0008441472891718149\n",
      "Epoch : 59000, loss : 0.0007457334431819618\n",
      "Epoch : 60000, loss : 0.000667072250507772\n",
      "Epoch : 61000, loss : 0.0006028208881616592\n",
      "Epoch : 62000, loss : 0.000549442833289504\n",
      "Epoch : 63000, loss : 0.0005044316640123725\n",
      "Epoch : 64000, loss : 0.0004659971746150404\n",
      "Epoch : 65000, loss : 0.0004327819333411753\n",
      "Epoch : 66000, loss : 0.00040384623571299016\n",
      "Epoch : 67000, loss : 0.0003784145519603044\n",
      "Epoch : 68000, loss : 0.00035583070712164044\n",
      "Epoch : 69000, loss : 0.00033573678229004145\n",
      "Epoch : 70000, loss : 0.00031775987008586526\n",
      "Epoch : 71000, loss : 0.0003015422262251377\n",
      "Epoch : 72000, loss : 0.00028683029813691974\n",
      "Epoch : 73000, loss : 0.00027340048109181225\n",
      "Epoch : 74000, loss : 0.0002611632226034999\n",
      "Epoch : 75000, loss : 0.00024992477847263217\n",
      "Epoch : 76000, loss : 0.0002396403724560514\n",
      "Epoch : 77000, loss : 0.00023008639982435852\n",
      "Epoch : 78000, loss : 0.0002212628605775535\n",
      "Epoch : 79000, loss : 0.00021306538837961853\n",
      "Epoch : 80000, loss : 0.00020544923609122634\n",
      "Epoch : 81000, loss : 0.00019829519442282617\n",
      "Epoch : 82000, loss : 0.0001916628098115325\n",
      "Epoch : 83000, loss : 0.0001854478323366493\n",
      "Epoch : 84000, loss : 0.00017963527352549136\n",
      "Epoch : 85000, loss : 0.00017409103747922927\n",
      "Epoch : 86000, loss : 0.00016891941777430475\n",
      "Epoch : 87000, loss : 0.00016401609173044562\n",
      "Epoch : 88000, loss : 0.00015936614363454282\n",
      "Epoch : 89000, loss : 0.0001549994049128145\n",
      "Epoch : 90000, loss : 0.00015087112842593342\n",
      "Epoch : 91000, loss : 0.0001469217095291242\n",
      "Epoch : 92000, loss : 0.00014316604938358068\n",
      "Epoch : 93000, loss : 0.00013961904915049672\n",
      "Epoch : 94000, loss : 0.00013619130186270922\n",
      "Epoch : 95000, loss : 0.00013294239761307836\n",
      "Epoch : 96000, loss : 0.00012987235095351934\n",
      "Epoch : 97000, loss : 0.00012690661242231727\n",
      "Epoch : 98000, loss : 0.00012406012683641165\n",
      "Epoch : 99000, loss : 0.0001213477662531659\n",
      "Epoch : 100000, loss : 0.00011875464406330138\n",
      "모델의 출력값 output \n",
      " [[1.04014965e-04]\n",
      " [9.99894381e-01]\n",
      " [9.99891281e-01]\n",
      " [1.56617549e-04]]\n",
      "모델의 예측값 output \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "실제값 (Y) \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "정확도 --> \n",
      " 1.0\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.BCELoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# 10000번의 epoch 실행\n",
    "epoch_number = 100000\n",
    "for epoch in range(epoch_number + 1) :\n",
    "    output = model(x) # 예측된 값\n",
    "\n",
    "    loss = criterion(output,y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 100의 배수에 해당되는 epoch마다 loss print\n",
    "    if epoch % 1000 == 0 :\n",
    "        print(f\"Epoch : {epoch}, loss : {loss.item()}\")\n",
    "\n",
    "# inference code\n",
    "with torch.no_grad() :\n",
    "    output = model(x)\n",
    "    predicted = (output > 0.5).float()\n",
    "    acc = (predicted==y).float().mean()\n",
    "    print(\"모델의 출력값 output \\n\", output.detach().cpu().numpy())\n",
    "    print(\"모델의 예측값 output \\n\", predicted.detach().cpu().numpy())\n",
    "    print(\"실제값 (Y) \\n\", y.cpu().numpy())\n",
    "    print(\"정확도 --> \\n\", acc.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e89c93e4c07d4ac8f065cea982a638287e1c61026788fcbbad7e0263e2130583"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
