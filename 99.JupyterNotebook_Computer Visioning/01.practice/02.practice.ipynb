{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.io import read_image\n",
    "\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file, names=['file_name', 'label'], skiprows=[0])\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        try:\n",
    "            image = read_image(img_path)\n",
    "        except:\n",
    "            print(self.img_labels.iloc[idx, 0])\n",
    "            exit()\n",
    "        label = int(self.img_labels.iloc[idx, 1])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Neural Networks Model.\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.fc5 = nn.Linear(64, 32)\n",
    "        self.fc6 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        h1 = F.relu(self.fc1(x.view(-1, 784)))\n",
    "        h2 = F.relu(self.fc2(h1))\n",
    "        h3 = F.relu(self.fc3(h2))\n",
    "        h4 = F.relu(self.fc4(h3))\n",
    "        h5 = F.relu(self.fc5(h4))\n",
    "        h6 = self.fc6(h5)\n",
    "        return F.log_softmax(h6, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init model done\n"
     ]
    }
   ],
   "source": [
    "#Prepare Data Loader for Training and Validation\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                 transforms.ToTensor(),\n",
    "                 transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "print(\"init model done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set vars and device done\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "lr = 0.01\n",
    "momentum = 0.5\n",
    "no_cuda = True\n",
    "seed = 1\n",
    "log_interval = 200\n",
    "\n",
    "use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "print(\"set vars and device done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "test_batch_size = 1000\n",
    "dataset = CustomImageDataset(\n",
    "    annotations_file='./data/FashionMNIST/annotations.csv',\n",
    "    img_dir='./data/FashionMNIST/imgs',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Change the dataset in test_loader to other scv file to check the result\n",
    "test_loader = torch.utils.data.DataLoader(dataset,\n",
    "    batch_size=test_batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(log_interval, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(log_interval, model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format\n",
    "          (test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.372018\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.378668\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.365031\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.303907\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.851829\n",
      "\n",
      "Test set: Average loss: 2.5930, Accuracy: 6000/60000 (10%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.709135\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 2.774677\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 3.235073\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 3.487649\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 4.158109\n",
      "\n",
      "Test set: Average loss: 5.0738, Accuracy: 6000/60000 (10%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 5.362549\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 4.753544\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 6.357253\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 5.970634\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 5.366640\n",
      "\n",
      "Test set: Average loss: 10.8377, Accuracy: 6000/60000 (10%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 8.729541\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 7.352942\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 11.286659\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 16.055756\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 13.689248\n",
      "\n",
      "Test set: Average loss: 11.7992, Accuracy: 6000/60000 (10%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 13.619987\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 19.032055\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 24.360394\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 13.939863\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 21.117159\n",
      "\n",
      "Test set: Average loss: 23.0031, Accuracy: 6000/60000 (10%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 24.491211\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 28.861483\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 28.846352\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 26.686171\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 30.041594\n",
      "\n",
      "Test set: Average loss: 24.6604, Accuracy: 6000/60000 (10%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 26.251472\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 25.037912\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 36.798691\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 42.971672\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 34.418148\n",
      "\n",
      "Test set: Average loss: 45.8267, Accuracy: 6000/60000 (10%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 46.121078\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 36.972305\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 30.339451\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 40.025146\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 54.600872\n",
      "\n",
      "Test set: Average loss: 54.1111, Accuracy: 6000/60000 (10%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 58.174667\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 44.415897\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 43.760792\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 65.478653\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 41.094090\n",
      "\n",
      "Test set: Average loss: 54.5053, Accuracy: 6000/60000 (10%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 49.574898\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 73.331123\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 79.881264\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 81.990959\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 42.948570\n",
      "\n",
      "Test set: Average loss: 74.1247, Accuracy: 6000/60000 (10%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 11):\n",
    "    train(log_interval, model, device, train_loader, optimizer, epoch)\n",
    "    test(log_interval, model, device, test_loader)\n",
    "torch.save(model, './model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(json_file, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m      2\u001b[0m     annotations_file \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'json_file' is not defined"
     ]
    }
   ],
   "source": [
    "with open(json_file, 'r') as f:\n",
    "    annotations_file = json.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb4569285eef3a3450cb62085a5b1e0da4bce0af555edc33dcf29baf3acc1368"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
