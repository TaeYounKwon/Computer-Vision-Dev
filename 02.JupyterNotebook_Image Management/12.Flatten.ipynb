{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 머신러닝 특성 만들기 \n",
    "\n",
    "• 이미지를 머신러닝에 필요한 샘플로 변환하려면 넘파이의 flatten()을 사용합니다.\n",
    "\n",
    "• Flatten()은 이미지 데이터가 담긴 다차원 배열을 샘플값이 담긴 벡터로 변환\n",
    "\n",
    "• 이미지가 흑백일 때 각 픽셀은 하나의 값으로 표현됩니다.\n",
    "\n",
    "• 컬럼 이미지라면 각 픽셀이 하나의 값이 아니라 여러 개의 값으로 표현됩니다.\n",
    "\n",
    "• 이미지의 모든 픽셀이 특성이 되기 때문에 이미지가 커질수록 특성의 개수도 크게 늘어납니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from utils import image_show\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([51, 14, 14, 19, 10,  7])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten Example\n",
    "x = np.array([[51,14],[14,19],[10,7]])\n",
    "x = x.flatten()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"./cat.jpg\"\n",
    "image_gray = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_10x10 = cv2.resize(image_gray, (10, 10))\n",
    "image_10x10.flatten()  # 이미지 데이터를 1차원 백터로 변환\n",
    "image_show(image_10x10)\n",
    "cv2.imwrite(\"12.cat_flatten.png\",image_10x10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([239, 230, 225, 242, 234, 227, 245, 239, 234, 248, 242, 237, 249,\n",
       "       242, 238,  35,  41,  60, 128, 129, 136, 250, 244, 240, 248, 244,\n",
       "       239, 248, 240, 233, 241, 237, 232,  72,  74,  99, 247, 241, 236,\n",
       "       249, 244, 239, 247, 242, 239,  58,  60,  79, 107, 111, 132, 251,\n",
       "       244, 241, 251, 244, 241, 248, 243, 238, 243, 239, 234,  32,  37,\n",
       "        66, 106, 109, 123, 188, 192, 194, 106, 111, 120,  74,  76,  89,\n",
       "       134, 136, 151, 253, 246, 243, 252, 245, 242, 251, 245, 240, 242,\n",
       "       238, 233, 129, 134, 147,  81,  81,  97,  85,  87,  97, 106, 111,\n",
       "       120, 106, 109, 117, 173, 178, 182, 251, 248, 244, 252, 248, 244,\n",
       "       252, 244, 242, 247, 242, 239, 247, 242, 239,  86,  89,  99,  92,\n",
       "        96, 101, 130, 133, 147,  57,  60,  37, 154, 161, 166, 252, 249,\n",
       "       245, 251, 248, 244, 251, 247, 243, 251, 246, 243, 251, 246, 243,\n",
       "       147, 153, 158,  55,  95,  43, 246, 246, 246, 175, 179, 184, 145,\n",
       "       150, 158, 251, 248, 244, 252, 248, 247, 253, 248, 245, 251, 248,\n",
       "       244, 252, 249, 245, 176, 179, 183, 173, 177, 178, 245, 244, 248,\n",
       "       202, 201, 203, 110, 116, 128, 252, 247, 244, 253, 249, 248, 252,\n",
       "       249, 245, 251, 248, 244, 252, 248, 246, 203, 204, 204, 238, 239,\n",
       "       237, 199, 199, 235, 236, 238, 238, 211, 217, 220, 191, 191, 192,\n",
       "       253, 251, 250, 255, 251, 250, 251, 248, 244, 253, 248, 249, 252,\n",
       "       248, 247, 229, 234, 235, 219, 222, 227, 187, 203, 221, 231, 236,\n",
       "       235, 248, 248, 248, 187, 187, 189, 252, 250, 249, 250, 249, 248,\n",
       "       252, 250, 249, 253, 250, 250, 246, 246, 246, 207, 219, 228, 210,\n",
       "       220, 228, 238, 243, 242, 252, 252, 252, 142, 143, 154, 253, 250,\n",
       "       250], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# image 10x10 픽셀 크기로 변환\n",
    "image_color_10x10 = cv2.resize(image, (10, 10))\n",
    "image_color_10x10.flatten()\n",
    "# image_show(image_color_10x10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# image 225x255 픽셀 크기로 변환\n",
    "image_color_225x255 = cv2.resize(image, (225, 255))\n",
    "image_color_225x255.flatten()\n",
    "image_show(image_color_225x255)\n",
    "cv2.imwrite(\"12.cat_flatten_color.png\",image_color_225x255)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e89c93e4c07d4ac8f065cea982a638287e1c61026788fcbbad7e0263e2130583"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
