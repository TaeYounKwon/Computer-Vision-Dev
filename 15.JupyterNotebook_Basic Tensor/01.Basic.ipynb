{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor 사용법\n",
    "\n",
    "- 텐서는 배열(array)나 행렬(matrix)과 매우 유사함\n",
    "\n",
    "- PyTorch에서는 텐서를 사용하여 모델의 입출력 + 모델의 매개변수를 부호화(encode)시켜줌\n",
    "\n",
    "- 텐서는 GPU나 다른 연산 가속을 위한 특수한 하드웨어에서 실행가능\n",
    "\n",
    "- Numpy의 ndarray와 매우 유사함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서 초기화하기\n",
    "\n",
    "- 데이터로부터 직접 텐서를 생성 가능\n",
    "- 데이터의 자료형은 자동으로 유추함\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[1,2],[3,4]]\n",
    "x_data = torch.tensor(data)\n",
    "x_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy 배열로 부터 탠서 생성\n",
    "\n",
    "- Numpy와 기본 배열 생성 후 torch.from_numpy를 통해 tensor로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy type:  <class 'numpy.ndarray'>\n",
      "Numpy -> torch:  <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array = np.array(data)\n",
    "print(\"numpy type: \",type(np_array))\n",
    "x_np = torch.from_numpy(np_array)\n",
    "print(\"Numpy -> torch: \",type(x_np))\n",
    "x_np.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor로 바뀐 데이터를 DataFrame으로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1\n",
       "0  1  2\n",
       "1  3  4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp = pd.DataFrame(x_data)\n",
    "dp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다른 텐서로부터 생성하기\n",
    "\n",
    "- 명시적으로 재정의(override)하지 않는다면, 인자로 주어진 텐서의 속성(모양(shape)), 자료형(datatype)을 유지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor >>\n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data) # x_data의 속성을 유지\n",
    "print(f\"Ones Tensor >>\\n\", x_ones, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8696, 0.7609],\n",
      "        [0.4650, 0.5283]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_rand = torch.rand_like(x_data, dtype= torch.float)# x_data의 속성을 덮어씁니다.\n",
    "print(x_rand, '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 무작위(random) 또는 상수(constant) 값을 사용하기\n",
    "\n",
    "- shape은 텐서의 차원(dimention)을 나타내는 튜플(tuple)타입으로, 아래 tensor들의 차원을 결정해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor >>\n",
      " tensor([[0.4653, 0.4375, 0.0548],\n",
      "        [0.8847, 0.8322, 0.8290],\n",
      "        [0.0489, 0.6955, 0.2814]]) \n",
      "\n",
      "Ones Tensor >>\n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor >>\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "shape = (3, 3) # shape 을 먼저 정해줌\n",
    "randn_tensor = torch.rand(shape)\n",
    "ones_tensor  = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor >>\\n\", randn_tensor, '\\n')\n",
    "print(f\"Ones Tensor >>\\n\"  , ones_tensor , '\\n')\n",
    "print(f\"Zeros Tensor >>\\n\" , zeros_tensor, '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서의 속성(Attribute)\n",
    "\n",
    "- 텐서의 속성은 텐서의 모양(shape), 자료형(datatype) 및 어느 장치에 저장되는지를 나타냄\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Data type of tensor: torch.float32\n",
      "Device tensor is stored on : cpu \n",
      "\n",
      "Random Tensor >> tensor([[0.2807, 0.8896, 0.7847, 0.1606],\n",
      "        [0.4159, 0.7166, 0.3224, 0.0517],\n",
      "        [0.5245, 0.8586, 0.6713, 0.8875]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3, 4) # shape을 직접 대입\n",
    "print(f\"Shape of tensor: {tensor.shape}\") # 모양\n",
    "print(f\"Data type of tensor: {tensor.dtype}\") # 타입\n",
    "print(f\"Device tensor is stored on : {tensor.device}\", '\\n') # 작동되는 하드웨어의 종류\n",
    "print(f\"Random Tensor >>\", tensor, '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서 연산(Operation)\n",
    "\n",
    "- 전치(transposing),인덱싱(indexing),슬라이싱(slicing),수학 계산,선형 대수,임의 샘플링(random sampling)등,100가지 이상의 텐서 연산들을 알려주는 링크\n",
    "    - https://pytorch.org/docs/stable/torch.html \n",
    "\n",
    "\n",
    "- 각 연산들은 (일반적으로 CPU보다 빠른)GPU에서 실행할 수 있습니다.\n",
    "\n",
    "- 아래는 GPU가 존재하면 텐서를 이동시키는 조건문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device tensor is stored on :  cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to('cuda')\n",
    "else:\n",
    "    tensor = tensor.to('cpu')\n",
    "print(\"Device tensor is stored on : \", tensor.device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor을 사용한 Numpy 식의 표준 인덱싱과 슬라이싱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 3., 1., 1.],\n",
      "        [1., 3., 1., 1.],\n",
      "        [1., 3., 1., 1.],\n",
      "        [1., 3., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor  = torch.ones((4,4))\n",
    "tensor[: , 1] = 3\n",
    "print(tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서 합치기 및 곱하기\n",
    "\n",
    "- 텐서를 합치기 위해 torch.cat()을 사용\n",
    "\n",
    "- 텐서의 곱은\n",
    "    - *을 사용해 요소별 곱을 계산\n",
    "    - @을 사용해 행렬 곱(matrix multiplication)을 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Original:\n",
      " tensor([[1, 2],\n",
      "        [3, 4]]) \n",
      "\n",
      "tensor 합치기:\n",
      " tensor([[1, 2, 1, 2],\n",
      "        [3, 4, 3, 4]]) \n",
      "\n",
      "tensor 곱하기(각 자리별):\n",
      " tensor([[ 1,  4],\n",
      "        [ 9, 16]]) \n",
      "\n",
      "tensor 곱하기(각 행렬별):\n",
      " tensor([[ 7, 10],\n",
      "        [15, 22]])\n"
     ]
    }
   ],
   "source": [
    "data = [[1,2],[3,4]]\n",
    "tensor  = torch.tensor(data)\n",
    "t1 = torch.cat([tensor, tensor], dim = 1)\n",
    "t2 = tensor * tensor\n",
    "t3 = tensor @ tensor\n",
    "\n",
    "print(\"Tensor Original:\\n\",tensor,\"\\n\")\n",
    "print(\"tensor 합치기:\\n\",t1, '\\n')\n",
    "print(\"tensor 곱하기(각 자리별):\\n\",t2, '\\n')\n",
    "print(\"tensor 곱하기(각 행렬별):\\n\",t3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor 바꿔치기 (in_place)\n",
    "\n",
    "- 연산 _접미사를 갖는 연산들은 바꿔치기(in-place) 연산입니다.\n",
    "\n",
    "- 예를 들어 x.copy()나 x.t_()는 x변경합니다.\n",
    "\n",
    "- 바꿔치기 연산은 메모리를 일부 절약하지만,기록(history)이 즉시 삭제되어 도함수(derivative)계산에 문제가 발생할 수 있습니다.\n",
    "    - *** 따라서,사용을 권장하지 않습니다. ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6., 6., 6., 6., 6.])\n"
     ]
    }
   ],
   "source": [
    "t  = torch.ones(5)\n",
    "t.add_(5)\n",
    "print(t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy 변환 (Bridge)\n",
    "\n",
    "- CPU 상의 텐서와 Numpy 배열은 메모리 공간을 공유하기 때문에, 하나를 변경하면 다른 하나도 변경됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  [1. 1. 1. 1. 1.]\n",
      "From numpy, add_(3):  tensor([4., 4., 4., 4., 4.], dtype=torch.float64)\n",
      "Original After:  [4. 4. 4. 4. 4.]\n",
      "From above, add(2):  tensor([6., 6., 6., 6., 6.], dtype=torch.float64)\n",
      "Original After:  [4. 4. 4. 4. 4.]\n"
     ]
    }
   ],
   "source": [
    "# 텐서의 변경사항이 Numpy에 적용됨\n",
    "n = np.ones(5)\n",
    "print(\"Original: \",n)\n",
    "t = torch.from_numpy(n)\n",
    "t.add_(3)\n",
    "v= t.add(2)\n",
    "print(\"From numpy, add_(3): \",t)\n",
    "print(\"Original After: \",n)\n",
    "print(\"From above, add(2): \",v)\n",
    "print(\"Original After: \",n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Numpy의 변경사항이 텐서에 적용됨\n",
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)\n",
    "np.add(n, 1, out = n)\n",
    "print(n)\n",
    "print(t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***중요*** View\n",
    "\n",
    "- View(뷰) - 원소의 수를 유지하면서 텐서의 크기 변경\n",
    "\n",
    "- 넘파이에서의 리쉐이프(Reshape)와 같은 역할을 함\n",
    "\n",
    "- 텐서의 크기를 변경해주는 역할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3])\n",
      "tensor([[[ 0.,  1.,  2.],\n",
      "         [ 3.,  4.,  5.]],\n",
      "\n",
      "        [[ 6.,  7.,  8.],\n",
      "         [ 9., 10., 11.]]])\n"
     ]
    }
   ],
   "source": [
    "# view\n",
    "t = np.array( [[[0,1,2], [3,4,5]], [[6,7,8], [9,10,11]]] )\n",
    "ft = torch.FloatTensor(t)\n",
    "print(ft.shape)\n",
    "print(ft)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View를 사용해서 3차원 -> 2차원\n",
    "\n",
    "- view([-1, 3])이 가지는 의미는 이와 같습니다. \n",
    "1. -1은 첫번째 차원은 사용자가 잘 모르겠으니 파이토치에 맡기겠다는 의미 \n",
    "2. 3은 두번째 차원의 길이는 3을 가지도록 하라는 의미입니다. 다시 말해 현재 3차원 텐서를 2차원 텐서로 변경하되 (?, 3)의 크기로 변경하라는 의미입니다. \n",
    "- 결과적으로 (4, 3)의 크기를 가지는 텐서를 얻었습니다.\n",
    "- 내부적으로 크기 변환은 다음과 같이 이루어졌습니다. (2, 2, 3) -> (2 × 2, 3) -> (4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: \n",
      " tensor([[[ 0.,  1.,  2.],\n",
      "         [ 3.,  4.,  5.]],\n",
      "\n",
      "        [[ 6.,  7.,  8.],\n",
      "         [ 9., 10., 11.]]])\n",
      "Original Shape:  torch.Size([2, 2, 3])\n",
      "\n",
      "Reshaped: \n",
      " tensor([[ 0.,  1.,  2.],\n",
      "        [ 3.,  4.,  5.],\n",
      "        [ 6.,  7.,  8.],\n",
      "        [ 9., 10., 11.]])\n",
      "Reshaped Shape:  torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "# 3차원 텐서-> 2차원 변경\n",
    "print(\"Original: \\n\",ft)\n",
    "print(\"Original Shape: \", ft.shape)\n",
    "\n",
    "new_tensor = ft.view([-1,3]) #ft라는 텐서를(?,3)의 크기로 변경\n",
    "\n",
    "print(\"\\nReshaped: \\n\", new_tensor)\n",
    "print(\"Reshaped Shape: \", new_tensor.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor 규칙 정리\n",
    "\n",
    "- view는 기본적으로 변경 전과 변경 후의 텐서 안의 원소의 개수가 유지되어야 합니다.\n",
    "\n",
    "- 파이토치의 view는 사이즈가 -1로 설정되면 다른 차원으로부터 해당 값을 유추합니다.\n",
    "\n",
    "- 변경 전 텐서의 원소의 수는 (2 × 2 × 3) = 12개 -> 변경 후 텐서의 원소의 개수 또한 (4 × 3) = 12개\n",
    "\n",
    "### 3차원 텐서의 크기 변경\n",
    "\n",
    "- 이번에는 3차원 텐서에서 3차원 텐서로 차원은 유지하되, 크기(shape)를 바꾸는 작업을 해보겠습니다. \n",
    "\n",
    "- view로 텐서의 크기를 변경하더라도 원소의 수는 유지되어야 한다고 언급한 바 있습니다.\n",
    "\n",
    "- 그렇다면 (2 × 2 × 3) 텐서를 (? × 1 × 3) 텐서로 변경하라고 하면 ?는 몇 차원인가요?\n",
    "    - (2 × 2 × 3) = (? × 1 × 3) = 12를 만족해야 하므로 ?는 4가 됩니다. 이를 실습으로 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  2.]],\n",
      "\n",
      "        [[ 3.,  4.,  5.]],\n",
      "\n",
      "        [[ 6.,  7.,  8.]],\n",
      "\n",
      "        [[ 9., 10., 11.]]])\n",
      "torch.Size([4, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "t = np.array( [[[0,1,2], [3,4,5]], [[6,7,8], [9,10,11]]] )\n",
    "ft = torch.FloatTensor(t)\n",
    "print(ft.view([-1, 1, 3]))\n",
    "print(ft.view([-1, 1, 3]).shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ft.squeeze() 스퀴즈 - 1차원 제거\n",
    "\n",
    "- 스퀴즈는 차원이 1인 경우에는 해당 차원을 제거합니다. 실습을 위해 임의로 (3 × 1)의 크기를 가지는 2차원 텐서를 만들겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [2.]])\n",
      "torch.Size([3, 1])\n",
      "tensor([0., 1., 2.])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# 3 x 1\n",
    "ft = torch.FloatTensor([[0], [1], [2]])\n",
    "print(ft)\n",
    "print(ft.shape)\n",
    "\n",
    "# 스퀴즈 : 1인 차원 제거\n",
    "print(ft.squeeze())\n",
    "print(ft.squeeze().shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ft.Unsqueeze 언스퀴즈 - 특정 위치에 1인 차원을 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.],\n",
      "         [1.],\n",
      "         [2.]]])\n",
      "torch.Size([1, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "# 언스퀴즈\n",
    "print(ft.unsqueeze(0))\n",
    "print(ft.unsqueeze(0).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e89c93e4c07d4ac8f065cea982a638287e1c61026788fcbbad7e0263e2130583"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
