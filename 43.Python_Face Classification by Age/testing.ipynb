{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import torch    \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from ex04_customdataset import CustomDataset\n",
    "from torchvision import models\n",
    "from ex05_main import model_try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = \"./dataset/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_function(correct, total) :\n",
    "    acc = correct / total * 100\n",
    "    return acc\n",
    "\n",
    "def test(model, data_loader, device) :\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (image, label, path) in enumerate(data_loader) :\n",
    "            images, labels = image.to(device), label.to(device)\n",
    "            output = model(images)\n",
    "            _, argmax = torch.max(output, 1)\n",
    "            total += images.size(0)\n",
    "            correct += (labels == argmax).sum().item()\n",
    "        acc = acc_function(correct, total)\n",
    "        print(f\"acc >> {acc}%\" )\n",
    "\n",
    "def test_show(test_loader, device) :\n",
    "    model = models.__dict__[\"resnet50\"](pretrained= True)\n",
    "    model.fc = nn.Linear(in_features = 2048, out_features = 6)\n",
    "    model.load_state_dict(torch.load(f'./best_{model_try}.pt', map_location=device)) # 경로 수정 필요\n",
    "    model.to(device)\n",
    "\n",
    "    \n",
    "    label_dict = folder_name_det(test_data_path)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad() :\n",
    "        for i, (imgs, labels, path) in enumerate(test_loader) :\n",
    "            inputs, outputs, paths = imgs.to(device), labels.to(device), path      \n",
    "            predicted_outputs = model(inputs)            \n",
    "            _, predicted = torch.max(predicted_outputs, 1) # 제일 확률 높은 답안지 내놔라\n",
    "\n",
    "            # total += images.size(0)\n",
    "            # correct += (labels == argmax).sum().item()\n",
    "\n",
    "            labels_temp = labels.item()\n",
    "            labels_pr_temp = predicted.item()\n",
    "\n",
    "            predicted_label = label_dict[str(labels_pr_temp)]\n",
    "            answer_label = label_dict[str(labels_temp)]\n",
    "        \n",
    "            img = cv2.imread(paths[0])\n",
    "            if(answer_label != predicted_label):  # label과 predicted output이 다를 경우멘 사진출력\n",
    "                print('Name of Label\\t:', paths[0].split('\\\\')[1])\n",
    "                print('Name of Image\\t:', paths[0].split('\\\\')[2])\n",
    "                print(\"Answer Label\\t:\" , answer_label)\n",
    "                print(\"Predicted Label\\t:\", predicted_label)\n",
    "                cv2.putText(img, predicted_label, (10, 20), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,0), 2) # 예상 답안 : 초록색\n",
    "                cv2.putText(img, answer_label, (10, 50), cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 2)    # 실제 답안 : 빨간색\n",
    "                cv2.imshow(\"test\", img)\n",
    "                cv2.waitKey(0)\n",
    "\n",
    "        # acc = acc_function(correct, total)\n",
    "        # print(f\"model accuracy >> {acc}%\" )\n",
    "\n",
    "def folder_name_det(folder_path) :\n",
    "    folder_name = glob.glob(os.path.join(folder_path,\"*\"))\n",
    "    det = {}\n",
    "    for index, (path) in enumerate(folder_name) :\n",
    "        temp_name = path.split(\"\\\\\")\n",
    "        temp_name = temp_name[1]\n",
    "        det[str(index)] = temp_name\n",
    "    return det          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39mload(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./best_\u001b[39m\u001b[39m{\u001b[39;00mmodel_try\u001b[39m}\u001b[39;00m\u001b[39m.pt\u001b[39m\u001b[39m'\u001b[39m, map_location\u001b[39m=\u001b[39mdevice))\n\u001b[0;32m     14\u001b[0m model\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m---> 16\u001b[0m test(model, test_loader, device)  \u001b[39m# 테스트 진행할때 실행 : 정확도 출력\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m====================================================================================\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     18\u001b[0m test_show(test_loader, device)  \u001b[39m# 틀린 label 이미지 확인하고 싶을 때 진행 : 사진 비교\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[17], line 10\u001b[0m, in \u001b[0;36mtest\u001b[1;34m(model, data_loader, device)\u001b[0m\n\u001b[0;32m      8\u001b[0m total \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m---> 10\u001b[0m     \u001b[39mfor\u001b[39;00m i, (image, label, path) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(data_loader) :\n\u001b[0;32m     11\u001b[0m         images, labels \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39mto(device), label\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     12\u001b[0m         output \u001b[39m=\u001b[39m model(images)\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "test_aug = A.Compose([\n",
    "        A.CenterCrop(width= 200, height= 200),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std= (0.229, 0.224, 0.225)),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "test_dataset = CustomDataset(\"./dataset/test\" , transform= test_aug)\n",
    "test_loader  = DataLoader(test_dataset, batch_size= 1, shuffle= False, num_workers= 2, pin_memory= True)\n",
    "\n",
    "###### 모델에 따라 수정 필요 !!!!\n",
    "model = models.__dict__[\"resnet50\"](pretrained= True)\n",
    "model.fc = nn.Linear(in_features = 2048, out_features = 6)\n",
    "model.load_state_dict(torch.load(f'./best_{model_try}.pt', map_location=device))\n",
    "model.to(device)\n",
    "\n",
    "test(model, test_loader, device)  # 테스트 진행할때 실행 : 정확도 출력\n",
    "print('====================================================================================')\n",
    "test_show(test_loader, device)  # 틀린 label 이미지 확인하고 싶을 때 진행 : 사진 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec1db613bd433334d4526401b52388526e3088498c79e7df5f78f6c21e8ddf15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
