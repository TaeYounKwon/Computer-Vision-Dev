{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 나눌 필요가 있음\n",
    "\n",
    "- 학습, 중간 평가, 테스트\n",
    "\n",
    "- 학습 8 중간 평가 1 테스트 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 이미지 폴더 가져오기(각 라벨별)\n",
    "\n",
    "- 데이터 량은 cloudy:1500, desert:1131, green_area:1500, water:1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 이미지 폴더 가져 오기\n",
    "img_cloudy_path = \"./data/cloudy\"\n",
    "img_cloudy = glob.glob(os.path.join(img_cloudy_path, \"*.jpg\"))\n",
    "\n",
    "img_desert_path = \"./data/desert\"\n",
    "img_desert = glob.glob(os.path.join(img_desert_path, \"*.jpg\"))\n",
    "\n",
    "img_green_area_path = \"./data/green_area\"\n",
    "img_green_area = glob.glob(os.path.join(img_green_area_path, \"*.jpg\"))\n",
    "\n",
    "img_water_path = \"./data/water\"\n",
    "img_water = glob.glob(os.path.join(img_water_path, \"*.jpg\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. train, val, test 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cloudy_train_list, cloudy_val_list \u001b[39m=\u001b[39m train_test_split(img_cloudy, test_size\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m, random_state\u001b[39m=\u001b[39;49m\u001b[39m7\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m cloudy_val_data, cloudy_test_data \u001b[39m=\u001b[39m train_test_split(cloudy_val_list, test_size\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m7\u001b[39m)\n\u001b[0;32m      4\u001b[0m desert_train_list, desert_val_list \u001b[39m=\u001b[39m train_test_split(img_desert, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m7\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\tempe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2448\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2445\u001b[0m arrays \u001b[39m=\u001b[39m indexable(\u001b[39m*\u001b[39marrays)\n\u001b[0;32m   2447\u001b[0m n_samples \u001b[39m=\u001b[39m _num_samples(arrays[\u001b[39m0\u001b[39m])\n\u001b[1;32m-> 2448\u001b[0m n_train, n_test \u001b[39m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2449\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[39m=\u001b[39;49m\u001b[39m0.25\u001b[39;49m\n\u001b[0;32m   2450\u001b[0m )\n\u001b[0;32m   2452\u001b[0m \u001b[39mif\u001b[39;00m shuffle \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m   2453\u001b[0m     \u001b[39mif\u001b[39;00m stratify \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\tempe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2126\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2123\u001b[0m n_train, n_test \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(n_train), \u001b[39mint\u001b[39m(n_test)\n\u001b[0;32m   2125\u001b[0m \u001b[39mif\u001b[39;00m n_train \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m-> 2126\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2127\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWith n_samples=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, test_size=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m and train_size=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2128\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2129\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39maforementioned parameters.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2130\u001b[0m     )\n\u001b[0;32m   2132\u001b[0m \u001b[39mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "cloudy_train_list, cloudy_val_list = train_test_split(img_cloudy, test_size=0.2, random_state=7)\n",
    "cloudy_val_data, cloudy_test_data = train_test_split(cloudy_val_list, test_size=0.5, random_state=7)\n",
    "\n",
    "desert_train_list, desert_val_list = train_test_split(img_desert, test_size=0.2, random_state=7)\n",
    "desert_val_data, desert_test_data = train_test_split(desert_val_list, test_size=0.5, random_state=7)\n",
    "\n",
    "green_area_train_list, green_area_val_list = train_test_split(img_green_area, test_size=0.2, random_state=7)\n",
    "green_area_val_data, green_area_test_data = train_test_split(green_area_val_list, test_size=0.5, random_state=7)\n",
    "\n",
    "water_train_list, water_val_list = train_test_split(img_water, test_size=0.2, random_state=7)\n",
    "water_val_data, water_test_data = train_test_split(water_val_list, test_size=0.5, random_state=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 각 폴더로 이미지 옮기기\n",
    "def data_save(data, mode) :\n",
    "    for path in data :\n",
    "        # image name\n",
    "        image_name = os.path.basename(path)\n",
    "        image_name = image_name.replace(\".jpg\", \"\")\n",
    "\n",
    "        # 0. 폴더명 구하기\n",
    "        folder_name = path.split(\"\\\\\")\n",
    "        folder_name = folder_name[0].split(\"/\")\n",
    "        print(folder_name)\n",
    "        folder_name = folder_name[2]\n",
    "        # 1. 폴더 구성\n",
    "        folder_path = f\"./dataset/{mode}/{folder_name}\"\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        # 2. 이미지 읽기\n",
    "        img = cv2.imread(path)\n",
    "        # 3. 이미지 저장\n",
    "        cv2.imwrite(os.path.join(folder_path, image_name+\".png\"),img)\n",
    "\n",
    "data_save(water_train_list, mode=\"train\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e89c93e4c07d4ac8f065cea982a638287e1c61026788fcbbad7e0263e2130583"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
